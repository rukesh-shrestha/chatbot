{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rukesh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model('chatbot_model.h5')\n",
    "import json\n",
    "import random\n",
    "\n",
    "intents = json.loads(open('all_data.json').read())\n",
    "words = pickle.load(open('words.pkl', 'rb'))\n",
    "classes = pickle.load(open('classes.pkl', 'rb'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern - split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word - create short form for word\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(sentence, words, show_details=False):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s:\n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_class(sentence):\n",
    "    # filter out predictions below a threshold\n",
    "    # p = bow(sentence, words,show_details=True)\n",
    "    res = model.predict(np.array([bow(sentence, words)]))[0]\n",
    "    ERROR_THRESHOLD = 0.50\n",
    "\n",
    "\n",
    "\n",
    "    results = [[i,r] for i,r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    # print(results)\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "    return_list = list()\n",
    "    for r in results:\n",
    "        # return_list.append((classes[r[0]], r[1]))\n",
    "        rr = [classes[r[0]]],[r[1]]\n",
    "        return_list.extend(rr)\n",
    "        # print(type(return_list))\n",
    "    return return_list\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> - hello\n",
      "hello sir/mam. how can we assist you?\n",
      "> - FUP\n",
      "sir, fup is right that every isp reserve. we are sure sooner or later it is going to be implemented by any isps according to their needs and requirements. so on with the increasing number of clients in worldlink we intend to provide the best possible internet experience to all our customers. for this, we rely on customers being fair in the way they use the internet. this \"fair usage policy\" is here to give us an option that if usage of any unlimited customer is excessive over a period of time to the point, it impacts on other users experience then the bandwidth will be capped to fallback speed and is effective only during peak hours (8pm to 11pm) whereas the speed remain unchanged beside mentioned timing.all of our valued clients must be able to use equal service. here, fup is an option to provide such solutions. there are so many users found they have been misusing internet e.g taking a connection for home and have been using for hostels, hotels, restaurants, multiple sharing and for other business purposes. if you take a deep look into it a normal users never falls under fup but all those bandwidth abusers and massive users.let us take 5 mbps package, when the internet usage exceeds the daily fup limit of 10 gb then fup will be applied during the daily peak hours ( i.e. 8 pm to 11 pm ), then the respective user will be notified via sms and e-mail. this will be done 3x3 times for every 10gb bandwidth usage during the daily peak hours with sms & email alert. for the next 3 times of 10 gb bandwidth usage, the bandwidth will then be capped to fallback speed ( 1 mbps) but users can reset the speed back to normal through mobile app or visiting our website. if the user continues with excessive use then the bandwidth will be capped again permanently ( i.e for 3 hours).when the internet usage is seen excessive then the respective users will be notified via sms and e-mail for 3 times, users can reset the speed back to normal via bandwidth selector option available in online service or mobile app for next 3 times. fup will be abolished as user manage his/her daily usage, if continuous excess usage is seen then the bandwidth will be capped permanently( i.e 8pm-11pm hours only).dear sir, its warning message for all of our customers with excessive internet usage. fup have not been implemented. whereas fup policy is a worldwide policy and also mentioned in point no. 20 of terms and conditions.let us take 5mbps package, when the internet usage exceeds the daily fup limit of 28 gb within the daily peak hours (i.e. 8pm-11pm), then the respective user will be notified via sms and email. this will be done 3*3 times for every 28gb bandwidth usage during the daily peak hours with sms and email alert. for the next 3 times of 28gb bandwidth usage, the bandwidth will then capped to fallback speed (3mbps) but users can reset the speed back to normal through mobile app or visiting our website. if the user continues with excessive use then the bandwidth will be capped again permanently (i.e. for 3 hours)at peak times, a lot of customers use the shared network bandwidth at any one time.this means that service quality for all users is affected, making it slower for everyone to access the internet or send and receive emails, especially at peak times. peak times may fluctuate between 8 pm to 11 pm. 5mbps- 20gb in 24hours- 1mbps fallback 10mbps- 24gb in 24hours- 2mbps fallback 20mbps- 28gb in 24hours- 3mbps fallback 25mbps- 32gb in 24hours- 4mbps fallback 30mbps- 36gb in 24hours- 5mbps fallback 35mbps- 36gb in 24hours- 5mbps fallback 40mbps- 36gb in 24hours- 5mbps fallback 50mbps- 40gb in 24hours- 6mbps fallback 55mbps- 40gb in 24hours- 6mbps fallback 60mbps- 40gb in 24hours- 6mbps fallback fup is applied only  if an excessive amount of data has been used in an account. our fup is applicable only from 8pm to 11 pm.\n",
      "> - okay\n",
      "sure sir.\n",
      "> - quit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def chat():\n",
    "    while True:\n",
    "        inp = input(\"> - \")\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "        results = predict_class(sentence=inp)\n",
    "\n",
    "        results_index = np.array(results)\n",
    "        tag = results_index[0]\n",
    "        list_of_intents = intents['intents']\n",
    "        for i in list_of_intents:\n",
    "            if (i['tag'] == tag):\n",
    "                result = random.choice(i['responses'])\n",
    "                break\n",
    "        print (result)\n",
    "    else:\n",
    "        print('gene')\n",
    "\n",
    "\n",
    "\n",
    "chat()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
