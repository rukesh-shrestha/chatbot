{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rukesh/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.models import load_model\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!']\n",
    "data_file = open('merged_json.json').read()\n",
    "intents = json.loads(data_file)\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "\n",
    "        # tokenize each word\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        # add documents in the corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 documents\n",
      "34 classes ['FUP', 'account', 'afternoon', 'branchoffice', 'cutcable', 'develop', 'evening', 'gameprice', 'gaming', 'hello', 'hi', 'hidessid', 'hosting', 'meaningofonline', 'morning', 'namastae', 'name', 'nettv', 'newconnection', 'offensive', 'okay', 'onlineservicespassword', 'pairremote', 'photoupload', 'portforward', 'renewconnection', 'safenet', 'secondaryrouter', 'services', 'slowconnection', 'thankyou', 'timeback', 'torrent', 'watchnettv']\n",
      "246 unique lemmatized words [',', '.', 'a', 'able', 'about', 'access', 'account', 'add', 'afternoon', 'also', 'am', 'amount', 'an', 'and', 'any', 'app/application', 'application', 'are', 'back', 'be', 'been', 'bhaster', 'bitch', 'block', 'branch', 'bro', 'browing', 'browsing', 'but', 'by', 'cable', 'can', 'certain', 'change', 'channel', 'claim', 'compensate', 'completely', 'connection', 'contact', 'contain', 'context', 'coorporation', 'could', 'csgo', 'customer', 'cut', 'day', 'declare', 'department', 'detail', 'develop', 'developer', 'did', 'do', 'document', 'educational', 'evening', 'exatly', 'existing', 'extend', 'facing', 'fair', 'fault', 'feature', 'feel', 'few', 'fiber', 'fifth', 'five/5', 'floor.i', 'for', 'fortnight', 'forward', 'friend', 'from', 'fuck', 'fucker', 'fup', 'fup/fair', 'game', 'gaming', 'gentelman', 'give', 'gta', 'gud', 'guide', 'ha', 'happy', 'have', 'head', 'heard', 'hello', 'hey', 'hi', 'hide', 'hosting', 'hour', 'how', 'i', 'idiot', 'if', 'in', 'internet', 'is', 'issue', 'it', 'joining', 'kamina', 'khate', 'know', 'kutta', 'laging', 'last', 'list', 'madargat', 'me', 'mean', 'mention', 'mind', 'mobile', 'month', 'morning', 'mother', 'mrg', 'mug', 'my', \"n't\", 'namaskar', 'namastae', 'namaste', 'name', 'need', 'nettv', 'new', 'night', 'not', 'notice', 'now', 'number', 'o', 'of', 'off', 'offen', 'oi', 'okay', 'old', 'one', 'online', 'open', 'opening', 'pair', 'password', 'past', 'pay', 'person', 'photo', 'ping', 'play', 'please', 'policy', 'port', 'post', 'prediction', 'price', 'prize', 'problem', 'provide', 'pubg', 'purpose', 'read', 'really', 'remote', 'renew', 'reset', 'router', 'safenet', 'sala', 'sale', 'say', 'secondary', 'send', 'serious', 'server', 'service', 'sevices', 'show', 'sir', 'sir/mam', 'slow', 'so', 'son', 'ssid', 'subscribe', 'suffering', 'suprise', 'system', 'tauko', 'teach', 'tell', 'tero', 'thank', 'that', 'the', 'there', 'this', 'time', 'to', 'today', 'torrent', 'tplink', 'truck', 'true', 'trying', 'tv', 'understand', 'upload', 'usage', 'use', 'user', 'using', 'v', 'vehicle', 'want', 'watch', 'way', 'we', 'web', 'well', 'what', 'while', 'who', 'why', 'wifi', 'wire', 'with', 'won', 'wordlink', 'work', 'working', 'worldink', 'worldlink', 'wrost', 'yes', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "# lemmaztize and lower each word and remove duplicates\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "# sort classes\n",
    "classes = sorted(list(set(classes)))\n",
    "# documents = combination between patterns and intents\n",
    "print(len(documents), \"documents\")\n",
    "# classes = intents\n",
    "print(len(classes), \"classes\", classes)\n",
    "# words = all words, vocabulary\n",
    "print(len(words), \"unique lemmatized words\", words)\n",
    "\n",
    "pickle.dump(words, open('words.pkl', 'wb'))\n",
    "pickle.dump(classes, open('classes.pkl', 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create our training data\n",
    "training = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # lemmatize each word - create base word, in attempt to represent related words\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array with 1, if word match found in current pattern\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "# create train and test lists. X - patterns, Y - intents\n",
    "train_x = list(training[:, 0])\n",
    "train_y = list(training[:, 1])\n",
    "print(\"Training data created\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rukesh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/700\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 3.5222 - accuracy: 0.0404\n",
      "Epoch 2/700\n",
      "99/99 [==============================] - 0s 400us/step - loss: 3.4611 - accuracy: 0.0404\n",
      "Epoch 3/700\n",
      "99/99 [==============================] - 0s 389us/step - loss: 3.3689 - accuracy: 0.1111\n",
      "Epoch 4/700\n",
      "99/99 [==============================] - 0s 271us/step - loss: 3.3523 - accuracy: 0.1414\n",
      "Epoch 5/700\n",
      "99/99 [==============================] - 0s 179us/step - loss: 3.1888 - accuracy: 0.2222\n",
      "Epoch 6/700\n",
      "99/99 [==============================] - 0s 180us/step - loss: 3.1702 - accuracy: 0.2020\n",
      "Epoch 7/700\n",
      "99/99 [==============================] - 0s 188us/step - loss: 3.1016 - accuracy: 0.2323\n",
      "Epoch 8/700\n",
      "99/99 [==============================] - 0s 185us/step - loss: 2.9560 - accuracy: 0.2323\n",
      "Epoch 9/700\n",
      "99/99 [==============================] - 0s 173us/step - loss: 2.9116 - accuracy: 0.2323\n",
      "Epoch 10/700\n",
      "99/99 [==============================] - 0s 175us/step - loss: 2.7963 - accuracy: 0.2929\n",
      "Epoch 11/700\n",
      "99/99 [==============================] - 0s 179us/step - loss: 2.6009 - accuracy: 0.3333\n",
      "Epoch 12/700\n",
      "99/99 [==============================] - 0s 193us/step - loss: 2.5587 - accuracy: 0.3232\n",
      "Epoch 13/700\n",
      "99/99 [==============================] - 0s 177us/step - loss: 2.3290 - accuracy: 0.4141\n",
      "Epoch 14/700\n",
      "99/99 [==============================] - 0s 165us/step - loss: 2.3170 - accuracy: 0.4343\n",
      "Epoch 15/700\n",
      "99/99 [==============================] - 0s 178us/step - loss: 2.1262 - accuracy: 0.4343\n",
      "Epoch 16/700\n",
      "99/99 [==============================] - 0s 144us/step - loss: 2.0769 - accuracy: 0.4040\n",
      "Epoch 17/700\n",
      "99/99 [==============================] - 0s 129us/step - loss: 2.0909 - accuracy: 0.4242\n",
      "Epoch 18/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 1.9879 - accuracy: 0.4949\n",
      "Epoch 19/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 2.0299 - accuracy: 0.4949\n",
      "Epoch 20/700\n",
      "99/99 [==============================] - 0s 126us/step - loss: 1.6163 - accuracy: 0.5960\n",
      "Epoch 21/700\n",
      "99/99 [==============================] - 0s 116us/step - loss: 1.5947 - accuracy: 0.5859\n",
      "Epoch 22/700\n",
      "99/99 [==============================] - 0s 129us/step - loss: 1.5866 - accuracy: 0.5354\n",
      "Epoch 23/700\n",
      "99/99 [==============================] - 0s 115us/step - loss: 1.4944 - accuracy: 0.5960\n",
      "Epoch 24/700\n",
      "99/99 [==============================] - 0s 118us/step - loss: 1.4777 - accuracy: 0.6465\n",
      "Epoch 25/700\n",
      "99/99 [==============================] - 0s 117us/step - loss: 1.2100 - accuracy: 0.6768\n",
      "Epoch 26/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 1.3101 - accuracy: 0.5960\n",
      "Epoch 27/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 1.2715 - accuracy: 0.6667\n",
      "Epoch 28/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 1.1555 - accuracy: 0.6869\n",
      "Epoch 29/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 1.1767 - accuracy: 0.6364\n",
      "Epoch 30/700\n",
      "99/99 [==============================] - 0s 116us/step - loss: 1.0449 - accuracy: 0.7778\n",
      "Epoch 31/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 1.0207 - accuracy: 0.7576\n",
      "Epoch 32/700\n",
      "99/99 [==============================] - 0s 128us/step - loss: 1.0668 - accuracy: 0.7071\n",
      "Epoch 33/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 1.1454 - accuracy: 0.6667\n",
      "Epoch 34/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.9830 - accuracy: 0.7273\n",
      "Epoch 35/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.9066 - accuracy: 0.7677\n",
      "Epoch 36/700\n",
      "99/99 [==============================] - 0s 116us/step - loss: 0.9715 - accuracy: 0.7374\n",
      "Epoch 37/700\n",
      "99/99 [==============================] - 0s 122us/step - loss: 0.8195 - accuracy: 0.7879\n",
      "Epoch 38/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.8471 - accuracy: 0.7172\n",
      "Epoch 39/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.7776 - accuracy: 0.7879\n",
      "Epoch 40/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.7368 - accuracy: 0.7980\n",
      "Epoch 41/700\n",
      "99/99 [==============================] - 0s 121us/step - loss: 0.7287 - accuracy: 0.8182\n",
      "Epoch 42/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.7709 - accuracy: 0.7778\n",
      "Epoch 43/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.7139 - accuracy: 0.8081\n",
      "Epoch 44/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.6017 - accuracy: 0.8485\n",
      "Epoch 45/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.7027 - accuracy: 0.7980\n",
      "Epoch 46/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.7854 - accuracy: 0.7475\n",
      "Epoch 47/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.5449 - accuracy: 0.8788\n",
      "Epoch 48/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.6079 - accuracy: 0.8384\n",
      "Epoch 49/700\n",
      "99/99 [==============================] - 0s 121us/step - loss: 0.6806 - accuracy: 0.7980\n",
      "Epoch 50/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.5973 - accuracy: 0.8384\n",
      "Epoch 51/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.5471 - accuracy: 0.8788\n",
      "Epoch 52/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.5891 - accuracy: 0.8384\n",
      "Epoch 53/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.6062 - accuracy: 0.7980\n",
      "Epoch 54/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.4558 - accuracy: 0.8788\n",
      "Epoch 55/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.5994 - accuracy: 0.8182\n",
      "Epoch 56/700\n",
      "99/99 [==============================] - 0s 122us/step - loss: 0.4571 - accuracy: 0.8788\n",
      "Epoch 57/700\n",
      "99/99 [==============================] - 0s 120us/step - loss: 0.4750 - accuracy: 0.8182\n",
      "Epoch 58/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.4484 - accuracy: 0.8485\n",
      "Epoch 59/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.4568 - accuracy: 0.8384\n",
      "Epoch 60/700\n",
      "99/99 [==============================] - 0s 124us/step - loss: 0.3035 - accuracy: 0.9091\n",
      "Epoch 61/700\n",
      "99/99 [==============================] - 0s 117us/step - loss: 0.4366 - accuracy: 0.8283\n",
      "Epoch 62/700\n",
      "99/99 [==============================] - 0s 119us/step - loss: 0.4628 - accuracy: 0.8586\n",
      "Epoch 63/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.4181 - accuracy: 0.9293\n",
      "Epoch 64/700\n",
      "99/99 [==============================] - 0s 115us/step - loss: 0.4150 - accuracy: 0.8889\n",
      "Epoch 65/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.3917 - accuracy: 0.9091\n",
      "Epoch 66/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.3847 - accuracy: 0.9091\n",
      "Epoch 67/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.2996 - accuracy: 0.9192\n",
      "Epoch 68/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.3672 - accuracy: 0.9192\n",
      "Epoch 69/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.4425 - accuracy: 0.8586\n",
      "Epoch 70/700\n",
      "99/99 [==============================] - 0s 97us/step - loss: 0.3820 - accuracy: 0.9091\n",
      "Epoch 71/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.4553 - accuracy: 0.8586\n",
      "Epoch 72/700\n",
      "99/99 [==============================] - 0s 116us/step - loss: 0.4298 - accuracy: 0.8788\n",
      "Epoch 73/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.3838 - accuracy: 0.8990\n",
      "Epoch 74/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.3877 - accuracy: 0.8990\n",
      "Epoch 75/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.4317 - accuracy: 0.8485\n",
      "Epoch 76/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.3197 - accuracy: 0.9394\n",
      "Epoch 77/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.3604 - accuracy: 0.8889\n",
      "Epoch 78/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.2904 - accuracy: 0.9091\n",
      "Epoch 79/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 117us/step - loss: 0.3125 - accuracy: 0.9091\n",
      "Epoch 80/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.3487 - accuracy: 0.8788\n",
      "Epoch 81/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.2979 - accuracy: 0.9192\n",
      "Epoch 82/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.4294 - accuracy: 0.8586\n",
      "Epoch 83/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.2431 - accuracy: 0.9495\n",
      "Epoch 84/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.3647 - accuracy: 0.8586\n",
      "Epoch 85/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.3598 - accuracy: 0.9091\n",
      "Epoch 86/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.3199 - accuracy: 0.9293\n",
      "Epoch 87/700\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 1.00 - 0s 107us/step - loss: 0.3302 - accuracy: 0.9091\n",
      "Epoch 88/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.3014 - accuracy: 0.9192\n",
      "Epoch 89/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.2833 - accuracy: 0.8990\n",
      "Epoch 90/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.4405 - accuracy: 0.8687\n",
      "Epoch 91/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.2838 - accuracy: 0.9091\n",
      "Epoch 92/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.2436 - accuracy: 0.9293\n",
      "Epoch 93/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.2197 - accuracy: 0.9293\n",
      "Epoch 94/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.2321 - accuracy: 0.9394\n",
      "Epoch 95/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.2066 - accuracy: 0.9697\n",
      "Epoch 96/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.2699 - accuracy: 0.8990\n",
      "Epoch 97/700\n",
      "99/99 [==============================] - 0s 93us/step - loss: 0.2336 - accuracy: 0.9495\n",
      "Epoch 98/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.2853 - accuracy: 0.9495\n",
      "Epoch 99/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.2278 - accuracy: 0.9394\n",
      "Epoch 100/700\n",
      "99/99 [==============================] - 0s 97us/step - loss: 0.2475 - accuracy: 0.9091\n",
      "Epoch 101/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.2233 - accuracy: 0.9293\n",
      "Epoch 102/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.3073 - accuracy: 0.9394\n",
      "Epoch 103/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.2403 - accuracy: 0.9596\n",
      "Epoch 104/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.3542 - accuracy: 0.8990\n",
      "Epoch 105/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.1677 - accuracy: 0.9495\n",
      "Epoch 106/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.2409 - accuracy: 0.9394\n",
      "Epoch 107/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.1533 - accuracy: 0.9596\n",
      "Epoch 108/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.2329 - accuracy: 0.9192\n",
      "Epoch 109/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.1763 - accuracy: 0.9495\n",
      "Epoch 110/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.2867 - accuracy: 0.9192\n",
      "Epoch 111/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.2337 - accuracy: 0.9495\n",
      "Epoch 112/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.2321 - accuracy: 0.9192\n",
      "Epoch 113/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.2938 - accuracy: 0.8990\n",
      "Epoch 114/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.2180 - accuracy: 0.9293\n",
      "Epoch 115/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.3122 - accuracy: 0.9091\n",
      "Epoch 116/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.1646 - accuracy: 0.9394\n",
      "Epoch 117/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.1404 - accuracy: 0.9697\n",
      "Epoch 118/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.1934 - accuracy: 0.9798\n",
      "Epoch 119/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.2155 - accuracy: 0.9293\n",
      "Epoch 120/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.2002 - accuracy: 0.9394\n",
      "Epoch 121/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.1570 - accuracy: 0.9798\n",
      "Epoch 122/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.2142 - accuracy: 0.9091\n",
      "Epoch 123/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.1245 - accuracy: 0.9495\n",
      "Epoch 124/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.1203 - accuracy: 0.9596\n",
      "Epoch 125/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.2441 - accuracy: 0.9394\n",
      "Epoch 126/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.2372 - accuracy: 0.9192\n",
      "Epoch 127/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.1402 - accuracy: 0.9798\n",
      "Epoch 128/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.3350 - accuracy: 0.9192\n",
      "Epoch 129/700\n",
      "99/99 [==============================] - 0s 118us/step - loss: 0.1695 - accuracy: 0.9394\n",
      "Epoch 130/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.2306 - accuracy: 0.9394\n",
      "Epoch 131/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.2079 - accuracy: 0.9192\n",
      "Epoch 132/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1749 - accuracy: 0.9697\n",
      "Epoch 133/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.1373 - accuracy: 0.9495\n",
      "Epoch 134/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.1618 - accuracy: 0.9798\n",
      "Epoch 135/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.2875 - accuracy: 0.9394\n",
      "Epoch 136/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.1689 - accuracy: 0.9495\n",
      "Epoch 137/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.3151 - accuracy: 0.8990\n",
      "Epoch 138/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.1761 - accuracy: 0.9192\n",
      "Epoch 139/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.2109 - accuracy: 0.9091\n",
      "Epoch 140/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.2136 - accuracy: 0.9192\n",
      "Epoch 141/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1020 - accuracy: 0.9798\n",
      "Epoch 142/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.2320 - accuracy: 0.9697\n",
      "Epoch 143/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.1518 - accuracy: 0.9596\n",
      "Epoch 144/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0879 - accuracy: 0.9697\n",
      "Epoch 145/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.1248 - accuracy: 0.9798\n",
      "Epoch 146/700\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 1.00 - 0s 111us/step - loss: 0.2134 - accuracy: 0.9495\n",
      "Epoch 147/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1481 - accuracy: 0.9697\n",
      "Epoch 148/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1195 - accuracy: 0.9798\n",
      "Epoch 149/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.1628 - accuracy: 0.9394\n",
      "Epoch 150/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1662 - accuracy: 0.9596\n",
      "Epoch 151/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.1333 - accuracy: 0.9596\n",
      "Epoch 152/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.2315 - accuracy: 0.9394\n",
      "Epoch 153/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1869 - accuracy: 0.9394\n",
      "Epoch 154/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.1549 - accuracy: 0.9596\n",
      "Epoch 155/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1640 - accuracy: 0.9293\n",
      "Epoch 156/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1510 - accuracy: 0.9596\n",
      "Epoch 157/700\n",
      "99/99 [==============================] - 0s 119us/step - loss: 0.1947 - accuracy: 0.9394\n",
      "Epoch 158/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 112us/step - loss: 0.1882 - accuracy: 0.9293\n",
      "Epoch 159/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.2482 - accuracy: 0.9394\n",
      "Epoch 160/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.1505 - accuracy: 0.9596\n",
      "Epoch 161/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.1317 - accuracy: 0.9596\n",
      "Epoch 162/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1588 - accuracy: 0.9596\n",
      "Epoch 163/700\n",
      "99/99 [==============================] - 0s 118us/step - loss: 0.1340 - accuracy: 0.9596\n",
      "Epoch 164/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.1363 - accuracy: 0.9899\n",
      "Epoch 165/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.1517 - accuracy: 0.9697\n",
      "Epoch 166/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0964 - accuracy: 0.9899\n",
      "Epoch 167/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0893 - accuracy: 0.9798\n",
      "Epoch 168/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.1584 - accuracy: 0.9495\n",
      "Epoch 169/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.1695 - accuracy: 0.9394\n",
      "Epoch 170/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.1669 - accuracy: 0.9596\n",
      "Epoch 171/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1844 - accuracy: 0.9293\n",
      "Epoch 172/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.1720 - accuracy: 0.9495\n",
      "Epoch 173/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0964 - accuracy: 0.9697\n",
      "Epoch 174/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.1563 - accuracy: 0.9596\n",
      "Epoch 175/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.1269 - accuracy: 0.9697\n",
      "Epoch 176/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.1334 - accuracy: 0.9798\n",
      "Epoch 177/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.1165 - accuracy: 0.9596\n",
      "Epoch 178/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1788 - accuracy: 0.9091\n",
      "Epoch 179/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.1442 - accuracy: 0.9697\n",
      "Epoch 180/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.1688 - accuracy: 0.9697\n",
      "Epoch 181/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1834 - accuracy: 0.9394\n",
      "Epoch 182/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0807 - accuracy: 0.9697\n",
      "Epoch 183/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.1606 - accuracy: 0.9394\n",
      "Epoch 184/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1142 - accuracy: 0.9697\n",
      "Epoch 185/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1744 - accuracy: 0.9394\n",
      "Epoch 186/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.1349 - accuracy: 0.9697\n",
      "Epoch 187/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.1146 - accuracy: 0.9596\n",
      "Epoch 188/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1159 - accuracy: 0.9697\n",
      "Epoch 189/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.1869 - accuracy: 0.9495\n",
      "Epoch 190/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.1768 - accuracy: 0.9596\n",
      "Epoch 191/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0808 - accuracy: 0.9697\n",
      "Epoch 192/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.1108 - accuracy: 0.9697\n",
      "Epoch 193/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.1371 - accuracy: 0.9697\n",
      "Epoch 194/700\n",
      "99/99 [==============================] - 0s 117us/step - loss: 0.1651 - accuracy: 0.9697\n",
      "Epoch 195/700\n",
      "99/99 [==============================] - 0s 122us/step - loss: 0.0893 - accuracy: 0.9899\n",
      "Epoch 196/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1672 - accuracy: 0.9495\n",
      "Epoch 197/700\n",
      "99/99 [==============================] - 0s 116us/step - loss: 0.1266 - accuracy: 0.9697\n",
      "Epoch 198/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.2363 - accuracy: 0.9394\n",
      "Epoch 199/700\n",
      "99/99 [==============================] - 0s 117us/step - loss: 0.1796 - accuracy: 0.9596\n",
      "Epoch 200/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.1635 - accuracy: 0.9495\n",
      "Epoch 201/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.1354 - accuracy: 0.9596\n",
      "Epoch 202/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1199 - accuracy: 0.9495\n",
      "Epoch 203/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.1147 - accuracy: 0.9697\n",
      "Epoch 204/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.1476 - accuracy: 0.9596\n",
      "Epoch 205/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.1171 - accuracy: 0.9596\n",
      "Epoch 206/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1015 - accuracy: 0.9798\n",
      "Epoch 207/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.1012 - accuracy: 0.9394\n",
      "Epoch 208/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.1090 - accuracy: 0.9697\n",
      "Epoch 209/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1075 - accuracy: 0.9697\n",
      "Epoch 210/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0957 - accuracy: 0.9798\n",
      "Epoch 211/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.1046 - accuracy: 0.9697\n",
      "Epoch 212/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.1158 - accuracy: 0.9495\n",
      "Epoch 213/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.1714 - accuracy: 0.9293\n",
      "Epoch 214/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0931 - accuracy: 0.9899\n",
      "Epoch 215/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1514 - accuracy: 0.9495\n",
      "Epoch 216/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.1159 - accuracy: 0.9697\n",
      "Epoch 217/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.1626 - accuracy: 0.9495\n",
      "Epoch 218/700\n",
      "99/99 [==============================] - 0s 117us/step - loss: 0.1139 - accuracy: 0.9697\n",
      "Epoch 219/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0791 - accuracy: 0.9798\n",
      "Epoch 220/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0935 - accuracy: 0.9697\n",
      "Epoch 221/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1613 - accuracy: 0.9495\n",
      "Epoch 222/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1374 - accuracy: 0.9697\n",
      "Epoch 223/700\n",
      "99/99 [==============================] - 0s 93us/step - loss: 0.0680 - accuracy: 0.9798\n",
      "Epoch 224/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0807 - accuracy: 0.9899\n",
      "Epoch 225/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.0821 - accuracy: 0.9697\n",
      "Epoch 226/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.1788 - accuracy: 0.9697\n",
      "Epoch 227/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1406 - accuracy: 0.9495\n",
      "Epoch 228/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0872 - accuracy: 0.9798\n",
      "Epoch 229/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0656 - accuracy: 0.9798\n",
      "Epoch 230/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.1261 - accuracy: 0.9596\n",
      "Epoch 231/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0911 - accuracy: 0.9596\n",
      "Epoch 232/700\n",
      "99/99 [==============================] - 0s 121us/step - loss: 0.0613 - accuracy: 0.9899\n",
      "Epoch 233/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.1030 - accuracy: 0.9596\n",
      "Epoch 234/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.1281 - accuracy: 0.9596\n",
      "Epoch 235/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.1079 - accuracy: 0.9697\n",
      "Epoch 236/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0725 - accuracy: 0.9798\n",
      "Epoch 237/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 108us/step - loss: 0.1419 - accuracy: 0.9495\n",
      "Epoch 238/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.1393 - accuracy: 0.9798\n",
      "Epoch 239/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.1191 - accuracy: 0.9596\n",
      "Epoch 240/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.1452 - accuracy: 0.9596\n",
      "Epoch 241/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.1511 - accuracy: 0.9596\n",
      "Epoch 242/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.1561 - accuracy: 0.9495\n",
      "Epoch 243/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.1219 - accuracy: 0.9596\n",
      "Epoch 244/700\n",
      "99/99 [==============================] - 0s 97us/step - loss: 0.1050 - accuracy: 0.9697\n",
      "Epoch 245/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0965 - accuracy: 0.9596\n",
      "Epoch 246/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0607 - accuracy: 0.9798\n",
      "Epoch 247/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.1195 - accuracy: 0.9596\n",
      "Epoch 248/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0468 - accuracy: 0.9798\n",
      "Epoch 249/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.1324 - accuracy: 0.9495\n",
      "Epoch 250/700\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.00 - 0s 107us/step - loss: 0.0406 - accuracy: 1.0000\n",
      "Epoch 251/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.1933 - accuracy: 0.9394\n",
      "Epoch 252/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0471 - accuracy: 1.0000\n",
      "Epoch 253/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0637 - accuracy: 1.0000\n",
      "Epoch 254/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.1184 - accuracy: 0.9596\n",
      "Epoch 255/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0900 - accuracy: 0.9596\n",
      "Epoch 256/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0692 - accuracy: 0.9899\n",
      "Epoch 257/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.1285 - accuracy: 0.9697\n",
      "Epoch 258/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0664 - accuracy: 0.9798\n",
      "Epoch 259/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.1096 - accuracy: 0.9697\n",
      "Epoch 260/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.1071 - accuracy: 0.9697\n",
      "Epoch 261/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0396 - accuracy: 1.0000\n",
      "Epoch 262/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.1279 - accuracy: 0.9697\n",
      "Epoch 263/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1079 - accuracy: 0.9798\n",
      "Epoch 264/700\n",
      "99/99 [==============================] - 0s 94us/step - loss: 0.0943 - accuracy: 0.9697\n",
      "Epoch 265/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0607 - accuracy: 0.9899\n",
      "Epoch 266/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0855 - accuracy: 0.9697\n",
      "Epoch 267/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0998 - accuracy: 0.9697\n",
      "Epoch 268/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0948 - accuracy: 0.9596\n",
      "Epoch 269/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.1419 - accuracy: 0.9697\n",
      "Epoch 270/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0956 - accuracy: 0.9798\n",
      "Epoch 271/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.1450 - accuracy: 0.9495\n",
      "Epoch 272/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0375 - accuracy: 1.0000\n",
      "Epoch 273/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0978 - accuracy: 0.9596\n",
      "Epoch 274/700\n",
      "99/99 [==============================] - 0s 94us/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 275/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0640 - accuracy: 0.9899\n",
      "Epoch 276/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.1054 - accuracy: 0.9697\n",
      "Epoch 277/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.1064 - accuracy: 0.9697\n",
      "Epoch 278/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0667 - accuracy: 0.9798\n",
      "Epoch 279/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1064 - accuracy: 0.9798\n",
      "Epoch 280/700\n",
      "99/99 [==============================] - 0s 94us/step - loss: 0.1220 - accuracy: 0.9596\n",
      "Epoch 281/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0690 - accuracy: 0.9798\n",
      "Epoch 282/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0735 - accuracy: 0.9798\n",
      "Epoch 283/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.1467 - accuracy: 0.9091\n",
      "Epoch 284/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0895 - accuracy: 0.9798\n",
      "Epoch 285/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1484 - accuracy: 0.9495\n",
      "Epoch 286/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0992 - accuracy: 0.9798\n",
      "Epoch 287/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1772 - accuracy: 0.9394\n",
      "Epoch 288/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.1223 - accuracy: 0.9596\n",
      "Epoch 289/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.1210 - accuracy: 0.9697\n",
      "Epoch 290/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.1179 - accuracy: 0.9697\n",
      "Epoch 291/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0855 - accuracy: 0.9899\n",
      "Epoch 292/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0440 - accuracy: 0.9899\n",
      "Epoch 293/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.0708 - accuracy: 0.9899\n",
      "Epoch 294/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0901 - accuracy: 0.9697\n",
      "Epoch 295/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0531 - accuracy: 0.9798\n",
      "Epoch 296/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.0885 - accuracy: 0.9899\n",
      "Epoch 297/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.1290 - accuracy: 0.9596\n",
      "Epoch 298/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1136 - accuracy: 0.9798\n",
      "Epoch 299/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.0837 - accuracy: 0.9697\n",
      "Epoch 300/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0375 - accuracy: 1.0000\n",
      "Epoch 301/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1564 - accuracy: 0.9596\n",
      "Epoch 302/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0787 - accuracy: 0.9697\n",
      "Epoch 303/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0827 - accuracy: 0.9798\n",
      "Epoch 304/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0723 - accuracy: 0.9899\n",
      "Epoch 305/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.1234 - accuracy: 0.9495\n",
      "Epoch 306/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0600 - accuracy: 0.9798\n",
      "Epoch 307/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0581 - accuracy: 0.9899\n",
      "Epoch 308/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0459 - accuracy: 0.9899\n",
      "Epoch 309/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.1101 - accuracy: 0.9495\n",
      "Epoch 310/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0971 - accuracy: 0.9596\n",
      "Epoch 311/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0845 - accuracy: 0.9697\n",
      "Epoch 312/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0815 - accuracy: 0.9798\n",
      "Epoch 313/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.0451 - accuracy: 0.9899\n",
      "Epoch 314/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0462 - accuracy: 0.9798\n",
      "Epoch 315/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.1421 - accuracy: 0.9495\n",
      "Epoch 316/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 100us/step - loss: 0.0624 - accuracy: 0.9798\n",
      "Epoch 317/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0456 - accuracy: 1.0000\n",
      "Epoch 318/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.1321 - accuracy: 0.9697\n",
      "Epoch 319/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0625 - accuracy: 0.9596\n",
      "Epoch 320/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0846 - accuracy: 0.9697\n",
      "Epoch 321/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.1083 - accuracy: 0.9697\n",
      "Epoch 322/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.0989 - accuracy: 0.9899\n",
      "Epoch 323/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0503 - accuracy: 0.9899\n",
      "Epoch 324/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 325/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0766 - accuracy: 0.9697\n",
      "Epoch 326/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0627 - accuracy: 0.9697\n",
      "Epoch 327/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0454 - accuracy: 0.9899\n",
      "Epoch 328/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.0381 - accuracy: 1.0000\n",
      "Epoch 329/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1788 - accuracy: 0.9394\n",
      "Epoch 330/700\n",
      "99/99 [==============================] - 0s 115us/step - loss: 0.1024 - accuracy: 0.9596\n",
      "Epoch 331/700\n",
      "99/99 [==============================] - 0s 117us/step - loss: 0.0777 - accuracy: 0.9899\n",
      "Epoch 332/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1007 - accuracy: 0.9798\n",
      "Epoch 333/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0726 - accuracy: 0.9899\n",
      "Epoch 334/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.0353 - accuracy: 1.0000\n",
      "Epoch 335/700\n",
      "99/99 [==============================] - 0s 115us/step - loss: 0.0979 - accuracy: 0.9697\n",
      "Epoch 336/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0610 - accuracy: 0.9798\n",
      "Epoch 337/700\n",
      "99/99 [==============================] - 0s 115us/step - loss: 0.0739 - accuracy: 0.9697\n",
      "Epoch 338/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.1246 - accuracy: 0.9394\n",
      "Epoch 339/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.1443 - accuracy: 0.9596\n",
      "Epoch 340/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0627 - accuracy: 0.9899\n",
      "Epoch 341/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0561 - accuracy: 0.9798\n",
      "Epoch 342/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.1352 - accuracy: 0.9697\n",
      "Epoch 343/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0953 - accuracy: 0.9596\n",
      "Epoch 344/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 345/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0855 - accuracy: 0.9697\n",
      "Epoch 346/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.1060 - accuracy: 0.9798\n",
      "Epoch 347/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0833 - accuracy: 0.9697\n",
      "Epoch 348/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.1148 - accuracy: 0.9596\n",
      "Epoch 349/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.0427 - accuracy: 1.0000\n",
      "Epoch 350/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0642 - accuracy: 0.9697\n",
      "Epoch 351/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0452 - accuracy: 0.9899\n",
      "Epoch 352/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.0623 - accuracy: 0.9899\n",
      "Epoch 353/700\n",
      "99/99 [==============================] - 0s 116us/step - loss: 0.0942 - accuracy: 0.9697\n",
      "Epoch 354/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.1040 - accuracy: 0.9495\n",
      "Epoch 355/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0849 - accuracy: 0.9697\n",
      "Epoch 356/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.0377 - accuracy: 0.9899\n",
      "Epoch 357/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0391 - accuracy: 0.9899\n",
      "Epoch 358/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0922 - accuracy: 0.9798\n",
      "Epoch 359/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 360/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.1129 - accuracy: 0.9697\n",
      "Epoch 361/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0936 - accuracy: 0.9899\n",
      "Epoch 362/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.1340 - accuracy: 0.9495\n",
      "Epoch 363/700\n",
      "99/99 [==============================] - 0s 117us/step - loss: 0.0510 - accuracy: 0.9899\n",
      "Epoch 364/700\n",
      "99/99 [==============================] - 0s 124us/step - loss: 0.0688 - accuracy: 0.9798\n",
      "Epoch 365/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1576 - accuracy: 0.9596\n",
      "Epoch 366/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0437 - accuracy: 0.9899\n",
      "Epoch 367/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.0571 - accuracy: 0.9899\n",
      "Epoch 368/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0402 - accuracy: 1.0000\n",
      "Epoch 369/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0696 - accuracy: 0.9697\n",
      "Epoch 370/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0317 - accuracy: 1.0000\n",
      "Epoch 371/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 372/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.0917 - accuracy: 0.9798\n",
      "Epoch 373/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.1060 - accuracy: 0.9697\n",
      "Epoch 374/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0749 - accuracy: 0.9596\n",
      "Epoch 375/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0700 - accuracy: 0.9798\n",
      "Epoch 376/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.0653 - accuracy: 0.9798\n",
      "Epoch 377/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0484 - accuracy: 0.9899\n",
      "Epoch 378/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.1288 - accuracy: 0.9596\n",
      "Epoch 379/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0809 - accuracy: 0.9697\n",
      "Epoch 380/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0637 - accuracy: 0.9798\n",
      "Epoch 381/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0561 - accuracy: 0.9899\n",
      "Epoch 382/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0901 - accuracy: 0.9798\n",
      "Epoch 383/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0667 - accuracy: 0.9798\n",
      "Epoch 384/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.0391 - accuracy: 1.0000\n",
      "Epoch 385/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0302 - accuracy: 0.9899\n",
      "Epoch 386/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0451 - accuracy: 0.9899\n",
      "Epoch 387/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0384 - accuracy: 0.9899\n",
      "Epoch 388/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0383 - accuracy: 0.9899\n",
      "Epoch 389/700\n",
      "99/99 [==============================] - 0s 118us/step - loss: 0.0360 - accuracy: 0.9798\n",
      "Epoch 390/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.1065 - accuracy: 0.9697\n",
      "Epoch 391/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.1132 - accuracy: 0.9697\n",
      "Epoch 392/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0455 - accuracy: 0.9899\n",
      "Epoch 393/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0632 - accuracy: 0.9798\n",
      "Epoch 394/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 395/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 106us/step - loss: 0.0568 - accuracy: 0.9899\n",
      "Epoch 396/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.0738 - accuracy: 0.9697\n",
      "Epoch 397/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0336 - accuracy: 0.9899\n",
      "Epoch 398/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0770 - accuracy: 0.9697\n",
      "Epoch 399/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0910 - accuracy: 0.9798\n",
      "Epoch 400/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0480 - accuracy: 0.9899\n",
      "Epoch 401/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 402/700\n",
      "99/99 [==============================] - 0s 117us/step - loss: 0.0420 - accuracy: 0.9798\n",
      "Epoch 403/700\n",
      "99/99 [==============================] - 0s 116us/step - loss: 0.0902 - accuracy: 0.9697\n",
      "Epoch 404/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.0980 - accuracy: 0.9697\n",
      "Epoch 405/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0549 - accuracy: 0.9798\n",
      "Epoch 406/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 407/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 408/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0236 - accuracy: 0.9899\n",
      "Epoch 409/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0914 - accuracy: 0.9798\n",
      "Epoch 410/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0607 - accuracy: 0.9798\n",
      "Epoch 411/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0489 - accuracy: 0.9899\n",
      "Epoch 412/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0632 - accuracy: 0.9899\n",
      "Epoch 413/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.0685 - accuracy: 0.9798\n",
      "Epoch 414/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0999 - accuracy: 0.9697\n",
      "Epoch 415/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0766 - accuracy: 0.9697\n",
      "Epoch 416/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.0415 - accuracy: 0.9899\n",
      "Epoch 417/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0676 - accuracy: 0.9596\n",
      "Epoch 418/700\n",
      "99/99 [==============================] - 0s 97us/step - loss: 0.0566 - accuracy: 0.9798\n",
      "Epoch 419/700\n",
      "99/99 [==============================] - 0s 115us/step - loss: 0.0594 - accuracy: 0.9899\n",
      "Epoch 420/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 421/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0435 - accuracy: 0.9798\n",
      "Epoch 422/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1164 - accuracy: 0.9596\n",
      "Epoch 423/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0896 - accuracy: 0.9798\n",
      "Epoch 424/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 425/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.2195 - accuracy: 0.9293\n",
      "Epoch 426/700\n",
      "99/99 [==============================] - 0s 117us/step - loss: 0.0613 - accuracy: 0.9899\n",
      "Epoch 427/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0353 - accuracy: 0.9899\n",
      "Epoch 428/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 429/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.0632 - accuracy: 0.9798\n",
      "Epoch 430/700\n",
      "99/99 [==============================] - 0s 115us/step - loss: 0.0418 - accuracy: 1.0000\n",
      "Epoch 431/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0777 - accuracy: 0.9697\n",
      "Epoch 432/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0643 - accuracy: 0.9798\n",
      "Epoch 433/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0223 - accuracy: 0.9899\n",
      "Epoch 434/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.0783 - accuracy: 0.9596\n",
      "Epoch 435/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0939 - accuracy: 0.9495\n",
      "Epoch 436/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0958 - accuracy: 0.9596\n",
      "Epoch 437/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.0608 - accuracy: 0.9798\n",
      "Epoch 438/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0550 - accuracy: 0.9798\n",
      "Epoch 439/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0634 - accuracy: 0.9798\n",
      "Epoch 440/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0442 - accuracy: 0.9899\n",
      "Epoch 441/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.1390 - accuracy: 0.9495\n",
      "Epoch 442/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 443/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0732 - accuracy: 0.9798\n",
      "Epoch 444/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0554 - accuracy: 0.9899\n",
      "Epoch 445/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.0678 - accuracy: 0.9697\n",
      "Epoch 446/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0975 - accuracy: 0.9495\n",
      "Epoch 447/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.1611 - accuracy: 0.9596\n",
      "Epoch 448/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0663 - accuracy: 0.9697\n",
      "Epoch 449/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.1329 - accuracy: 0.9596\n",
      "Epoch 450/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0600 - accuracy: 0.9596\n",
      "Epoch 451/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0766 - accuracy: 0.9798\n",
      "Epoch 452/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0673 - accuracy: 0.9697\n",
      "Epoch 453/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.1014 - accuracy: 0.9798\n",
      "Epoch 454/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0463 - accuracy: 0.9798\n",
      "Epoch 455/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.0994 - accuracy: 0.9697\n",
      "Epoch 456/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0748 - accuracy: 0.9798\n",
      "Epoch 457/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1288 - accuracy: 0.9495\n",
      "Epoch 458/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.0921 - accuracy: 0.9697\n",
      "Epoch 459/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0381 - accuracy: 0.9798\n",
      "Epoch 460/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0206 - accuracy: 0.9899\n",
      "Epoch 461/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0590 - accuracy: 0.9899\n",
      "Epoch 462/700\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.1464 - accuracy: 0.87 - 0s 108us/step - loss: 0.0788 - accuracy: 0.9596\n",
      "Epoch 463/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0839 - accuracy: 0.9697\n",
      "Epoch 464/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0635 - accuracy: 0.9798\n",
      "Epoch 465/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.0708 - accuracy: 0.9798\n",
      "Epoch 466/700\n",
      "99/99 [==============================] - 0s 116us/step - loss: 0.0413 - accuracy: 0.9899\n",
      "Epoch 467/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 468/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.1086 - accuracy: 0.9697\n",
      "Epoch 469/700\n",
      "99/99 [==============================] - 0s 115us/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 470/700\n",
      "99/99 [==============================] - 0s 116us/step - loss: 0.0666 - accuracy: 0.9798\n",
      "Epoch 471/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.1116 - accuracy: 0.9798\n",
      "Epoch 472/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.1471 - accuracy: 0.9394\n",
      "Epoch 473/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0794 - accuracy: 0.9899\n",
      "Epoch 474/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 116us/step - loss: 0.0433 - accuracy: 0.9899\n",
      "Epoch 475/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1460 - accuracy: 0.9394\n",
      "Epoch 476/700\n",
      "99/99 [==============================] - 0s 115us/step - loss: 0.0660 - accuracy: 0.9899\n",
      "Epoch 477/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 478/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0543 - accuracy: 0.9899\n",
      "Epoch 479/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.1435 - accuracy: 0.9394\n",
      "Epoch 480/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0503 - accuracy: 0.9798\n",
      "Epoch 481/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0711 - accuracy: 0.9798\n",
      "Epoch 482/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 483/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 484/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1078 - accuracy: 0.9697\n",
      "Epoch 485/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0704 - accuracy: 0.9899\n",
      "Epoch 486/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.0800 - accuracy: 0.9697\n",
      "Epoch 487/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0914 - accuracy: 0.9798\n",
      "Epoch 488/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.0494 - accuracy: 0.9798\n",
      "Epoch 489/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.1096 - accuracy: 0.9697\n",
      "Epoch 490/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0558 - accuracy: 0.9798\n",
      "Epoch 491/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0648 - accuracy: 0.9697\n",
      "Epoch 492/700\n",
      "99/99 [==============================] - 0s 97us/step - loss: 0.0896 - accuracy: 0.9596\n",
      "Epoch 493/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0814 - accuracy: 0.9596\n",
      "Epoch 494/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0794 - accuracy: 0.9798\n",
      "Epoch 495/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0504 - accuracy: 0.9899\n",
      "Epoch 496/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 497/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.1087 - accuracy: 0.9697\n",
      "Epoch 498/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0918 - accuracy: 0.9798\n",
      "Epoch 499/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.0439 - accuracy: 0.9798\n",
      "Epoch 500/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0437 - accuracy: 1.0000\n",
      "Epoch 501/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0466 - accuracy: 0.9899\n",
      "Epoch 502/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0300 - accuracy: 0.9899\n",
      "Epoch 503/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0502 - accuracy: 0.9798\n",
      "Epoch 504/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0401 - accuracy: 0.9899\n",
      "Epoch 505/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 506/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.1211 - accuracy: 0.9596\n",
      "Epoch 507/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 508/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.0437 - accuracy: 0.9899\n",
      "Epoch 509/700\n",
      "99/99 [==============================] - 0s 93us/step - loss: 0.0813 - accuracy: 0.9697\n",
      "Epoch 510/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0436 - accuracy: 0.9798\n",
      "Epoch 511/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0443 - accuracy: 0.9899\n",
      "Epoch 512/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0878 - accuracy: 0.9798\n",
      "Epoch 513/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0621 - accuracy: 0.9798\n",
      "Epoch 514/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0473 - accuracy: 0.9798\n",
      "Epoch 515/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.0327 - accuracy: 0.9899\n",
      "Epoch 516/700\n",
      "99/99 [==============================] - 0s 146us/step - loss: 0.0885 - accuracy: 0.9697\n",
      "Epoch 517/700\n",
      "99/99 [==============================] - 0s 127us/step - loss: 0.0922 - accuracy: 0.9798\n",
      "Epoch 518/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0467 - accuracy: 0.9798\n",
      "Epoch 519/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0518 - accuracy: 0.9798\n",
      "Epoch 520/700\n",
      "99/99 [==============================] - 0s 97us/step - loss: 0.0201 - accuracy: 0.9899\n",
      "Epoch 521/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0890 - accuracy: 0.9596\n",
      "Epoch 522/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0380 - accuracy: 0.9899\n",
      "Epoch 523/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0364 - accuracy: 0.9899\n",
      "Epoch 524/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 525/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0648 - accuracy: 0.9798\n",
      "Epoch 526/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0459 - accuracy: 0.9899\n",
      "Epoch 527/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0718 - accuracy: 0.9798\n",
      "Epoch 528/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0561 - accuracy: 0.9899\n",
      "Epoch 529/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.0451 - accuracy: 0.9899\n",
      "Epoch 530/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.0644 - accuracy: 0.9697\n",
      "Epoch 531/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0275 - accuracy: 0.9899\n",
      "Epoch 532/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0368 - accuracy: 0.9899\n",
      "Epoch 533/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0291 - accuracy: 0.9899\n",
      "Epoch 534/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0769 - accuracy: 0.9495\n",
      "Epoch 535/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0393 - accuracy: 0.9798\n",
      "Epoch 536/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0564 - accuracy: 0.9899\n",
      "Epoch 537/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0540 - accuracy: 0.9798\n",
      "Epoch 538/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 539/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.0905 - accuracy: 0.9596\n",
      "Epoch 540/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0469 - accuracy: 0.9697\n",
      "Epoch 541/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0301 - accuracy: 0.9899\n",
      "Epoch 542/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1092 - accuracy: 0.9798\n",
      "Epoch 543/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0548 - accuracy: 0.9899\n",
      "Epoch 544/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0433 - accuracy: 0.9899\n",
      "Epoch 545/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0467 - accuracy: 0.9798\n",
      "Epoch 546/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0510 - accuracy: 0.9899\n",
      "Epoch 547/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.1050 - accuracy: 0.9697\n",
      "Epoch 548/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0545 - accuracy: 0.9798\n",
      "Epoch 549/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0383 - accuracy: 1.0000\n",
      "Epoch 550/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.0567 - accuracy: 0.9899\n",
      "Epoch 551/700\n",
      "99/99 [==============================] - 0s 120us/step - loss: 0.0344 - accuracy: 0.9899\n",
      "Epoch 552/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0434 - accuracy: 0.9899\n",
      "Epoch 553/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 113us/step - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 554/700\n",
      "99/99 [==============================] - 0s 134us/step - loss: 0.0707 - accuracy: 0.9798\n",
      "Epoch 555/700\n",
      "99/99 [==============================] - 0s 117us/step - loss: 0.0733 - accuracy: 0.9798\n",
      "Epoch 556/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0434 - accuracy: 0.9899\n",
      "Epoch 557/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.1056 - accuracy: 0.9697\n",
      "Epoch 558/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0816 - accuracy: 0.9798\n",
      "Epoch 559/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0337 - accuracy: 1.0000\n",
      "Epoch 560/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.0560 - accuracy: 0.9798\n",
      "Epoch 561/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0293 - accuracy: 0.9899\n",
      "Epoch 562/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0283 - accuracy: 0.9899\n",
      "Epoch 563/700\n",
      "99/99 [==============================] - 0s 117us/step - loss: 0.0595 - accuracy: 0.9798\n",
      "Epoch 564/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0552 - accuracy: 0.9899\n",
      "Epoch 565/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.1046 - accuracy: 0.9495\n",
      "Epoch 566/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0601 - accuracy: 0.9798\n",
      "Epoch 567/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0568 - accuracy: 0.9697\n",
      "Epoch 568/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 569/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 570/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0309 - accuracy: 0.9899\n",
      "Epoch 571/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.0825 - accuracy: 0.9798\n",
      "Epoch 572/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0391 - accuracy: 0.9899\n",
      "Epoch 573/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 574/700\n",
      "99/99 [==============================] - 0s 97us/step - loss: 0.0873 - accuracy: 0.9495\n",
      "Epoch 575/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.1168 - accuracy: 0.9798\n",
      "Epoch 576/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0380 - accuracy: 0.9899\n",
      "Epoch 577/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 578/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0482 - accuracy: 0.9899\n",
      "Epoch 579/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0376 - accuracy: 0.9798\n",
      "Epoch 580/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0822 - accuracy: 0.9697\n",
      "Epoch 581/700\n",
      "99/99 [==============================] - 0s 95us/step - loss: 0.0599 - accuracy: 0.9798\n",
      "Epoch 582/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0482 - accuracy: 0.9697\n",
      "Epoch 583/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0326 - accuracy: 0.9899\n",
      "Epoch 584/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.0705 - accuracy: 0.9697\n",
      "Epoch 585/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0850 - accuracy: 0.9798\n",
      "Epoch 586/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.1053 - accuracy: 0.9697\n",
      "Epoch 587/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0421 - accuracy: 0.9798\n",
      "Epoch 588/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0764 - accuracy: 0.9697\n",
      "Epoch 589/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0250 - accuracy: 0.9899\n",
      "Epoch 590/700\n",
      "99/99 [==============================] - 0s 95us/step - loss: 0.0395 - accuracy: 0.9899\n",
      "Epoch 591/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0444 - accuracy: 0.9899\n",
      "Epoch 592/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0485 - accuracy: 0.9798\n",
      "Epoch 593/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.0427 - accuracy: 0.9798\n",
      "Epoch 594/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 595/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0566 - accuracy: 0.9697\n",
      "Epoch 596/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0397 - accuracy: 0.9899\n",
      "Epoch 597/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0379 - accuracy: 0.9899\n",
      "Epoch 598/700\n",
      "99/99 [==============================] - 0s 116us/step - loss: 0.0768 - accuracy: 0.9798\n",
      "Epoch 599/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0239 - accuracy: 0.9899\n",
      "Epoch 600/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0358 - accuracy: 0.9899\n",
      "Epoch 601/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 602/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0572 - accuracy: 0.9798\n",
      "Epoch 603/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0600 - accuracy: 0.9899\n",
      "Epoch 604/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.1427 - accuracy: 0.9495\n",
      "Epoch 605/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0479 - accuracy: 0.9899\n",
      "Epoch 606/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0575 - accuracy: 0.9798\n",
      "Epoch 607/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0442 - accuracy: 0.9798\n",
      "Epoch 608/700\n",
      "99/99 [==============================] - 0s 94us/step - loss: 0.1070 - accuracy: 0.9697\n",
      "Epoch 609/700\n",
      "99/99 [==============================] - 0s 97us/step - loss: 0.0439 - accuracy: 0.9899\n",
      "Epoch 610/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.1515 - accuracy: 0.9394\n",
      "Epoch 611/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.0766 - accuracy: 0.9798\n",
      "Epoch 612/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.1111 - accuracy: 0.9697\n",
      "Epoch 613/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 614/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0873 - accuracy: 0.9495\n",
      "Epoch 615/700\n",
      "99/99 [==============================] - 0s 97us/step - loss: 0.0909 - accuracy: 0.9697\n",
      "Epoch 616/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.1130 - accuracy: 0.9899\n",
      "Epoch 617/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0398 - accuracy: 0.9899\n",
      "Epoch 618/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0293 - accuracy: 0.9899\n",
      "Epoch 619/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0665 - accuracy: 0.9798\n",
      "Epoch 620/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0322 - accuracy: 0.9798\n",
      "Epoch 621/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.1198 - accuracy: 0.9697\n",
      "Epoch 622/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0733 - accuracy: 0.9596\n",
      "Epoch 623/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0511 - accuracy: 0.9697\n",
      "Epoch 624/700\n",
      "99/99 [==============================] - 0s 98us/step - loss: 0.0336 - accuracy: 0.9798\n",
      "Epoch 625/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0429 - accuracy: 0.9798\n",
      "Epoch 626/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1218 - accuracy: 0.9596\n",
      "Epoch 627/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1646 - accuracy: 0.9394\n",
      "Epoch 628/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.1306 - accuracy: 0.9495\n",
      "Epoch 629/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0351 - accuracy: 0.9798\n",
      "Epoch 630/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0362 - accuracy: 1.0000\n",
      "Epoch 631/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0241 - accuracy: 0.9899\n",
      "Epoch 632/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 106us/step - loss: 0.0772 - accuracy: 0.9798\n",
      "Epoch 633/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0327 - accuracy: 0.9899\n",
      "Epoch 634/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0359 - accuracy: 0.9899\n",
      "Epoch 635/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0554 - accuracy: 0.9899\n",
      "Epoch 636/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0919 - accuracy: 0.9596\n",
      "Epoch 637/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0670 - accuracy: 0.9697\n",
      "Epoch 638/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0701 - accuracy: 0.9899\n",
      "Epoch 639/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 640/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.1871 - accuracy: 0.9495\n",
      "Epoch 641/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0408 - accuracy: 0.9899\n",
      "Epoch 642/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 643/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0647 - accuracy: 0.9798\n",
      "Epoch 644/700\n",
      "99/99 [==============================] - 0s 118us/step - loss: 0.0364 - accuracy: 1.0000\n",
      "Epoch 645/700\n",
      "99/99 [==============================] - 0s 124us/step - loss: 0.1032 - accuracy: 0.9596\n",
      "Epoch 646/700\n",
      "99/99 [==============================] - 0s 124us/step - loss: 0.0454 - accuracy: 0.9798\n",
      "Epoch 647/700\n",
      "99/99 [==============================] - 0s 122us/step - loss: 0.1180 - accuracy: 0.9697\n",
      "Epoch 648/700\n",
      "99/99 [==============================] - 0s 128us/step - loss: 0.0743 - accuracy: 0.9697\n",
      "Epoch 649/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0759 - accuracy: 0.9697\n",
      "Epoch 650/700\n",
      "99/99 [==============================] - 0s 120us/step - loss: 0.0474 - accuracy: 0.9798\n",
      "Epoch 651/700\n",
      "99/99 [==============================] - 0s 129us/step - loss: 0.0395 - accuracy: 1.0000\n",
      "Epoch 652/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0676 - accuracy: 0.9899\n",
      "Epoch 653/700\n",
      "99/99 [==============================] - 0s 117us/step - loss: 0.0631 - accuracy: 0.9899\n",
      "Epoch 654/700\n",
      "99/99 [==============================] - 0s 122us/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 655/700\n",
      "99/99 [==============================] - 0s 120us/step - loss: 0.0999 - accuracy: 0.9697\n",
      "Epoch 656/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 657/700\n",
      "99/99 [==============================] - 0s 111us/step - loss: 0.0873 - accuracy: 0.9697\n",
      "Epoch 658/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.1092 - accuracy: 0.9798\n",
      "Epoch 659/700\n",
      "99/99 [==============================] - 0s 120us/step - loss: 0.1298 - accuracy: 0.9596\n",
      "Epoch 660/700\n",
      "99/99 [==============================] - 0s 118us/step - loss: 0.0545 - accuracy: 0.9798\n",
      "Epoch 661/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0824 - accuracy: 0.9697\n",
      "Epoch 662/700\n",
      "99/99 [==============================] - 0s 95us/step - loss: 0.0306 - accuracy: 0.9899\n",
      "Epoch 663/700\n",
      "99/99 [==============================] - 0s 109us/step - loss: 0.0348 - accuracy: 0.9899\n",
      "Epoch 664/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0752 - accuracy: 0.9899\n",
      "Epoch 665/700\n",
      "99/99 [==============================] - 0s 99us/step - loss: 0.0475 - accuracy: 0.9899\n",
      "Epoch 666/700\n",
      "99/99 [==============================] - 0s 110us/step - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 667/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0572 - accuracy: 0.9798\n",
      "Epoch 668/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0683 - accuracy: 0.9798\n",
      "Epoch 669/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 670/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0702 - accuracy: 0.9596\n",
      "Epoch 671/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0359 - accuracy: 0.9697\n",
      "Epoch 672/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.1025 - accuracy: 0.9798\n",
      "Epoch 673/700\n",
      "99/99 [==============================] - 0s 113us/step - loss: 0.0286 - accuracy: 0.9899\n",
      "Epoch 674/700\n",
      "99/99 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 1.00 - 0s 105us/step - loss: 0.0654 - accuracy: 0.9697\n",
      "Epoch 675/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 676/700\n",
      "99/99 [==============================] - 0s 112us/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 677/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0295 - accuracy: 0.9899\n",
      "Epoch 678/700\n",
      "99/99 [==============================] - 0s 101us/step - loss: 0.0617 - accuracy: 0.9899\n",
      "Epoch 679/700\n",
      "99/99 [==============================] - 0s 100us/step - loss: 0.0267 - accuracy: 0.9899\n",
      "Epoch 680/700\n",
      "99/99 [==============================] - 0s 114us/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 681/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 682/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0773 - accuracy: 0.9697\n",
      "Epoch 683/700\n",
      "99/99 [==============================] - 0s 104us/step - loss: 0.0359 - accuracy: 0.9899\n",
      "Epoch 684/700\n",
      "99/99 [==============================] - 0s 105us/step - loss: 0.0554 - accuracy: 0.9798\n",
      "Epoch 685/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.1243 - accuracy: 0.9596\n",
      "Epoch 686/700\n",
      "99/99 [==============================] - 0s 103us/step - loss: 0.0687 - accuracy: 0.9899\n",
      "Epoch 687/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0378 - accuracy: 0.9899\n",
      "Epoch 688/700\n",
      "99/99 [==============================] - 0s 94us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 689/700\n",
      "99/99 [==============================] - 0s 106us/step - loss: 0.0666 - accuracy: 0.9697\n",
      "Epoch 690/700\n",
      "99/99 [==============================] - 0s 102us/step - loss: 0.0854 - accuracy: 0.9697\n",
      "Epoch 691/700\n",
      "99/99 [==============================] - 0s 96us/step - loss: 0.0516 - accuracy: 0.9798\n",
      "Epoch 692/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0990 - accuracy: 0.9899\n",
      "Epoch 693/700\n",
      "99/99 [==============================] - 0s 118us/step - loss: 0.0952 - accuracy: 0.9596\n",
      "Epoch 694/700\n",
      "99/99 [==============================] - 0s 116us/step - loss: 0.0295 - accuracy: 0.9899\n",
      "Epoch 695/700\n",
      "99/99 [==============================] - 0s 107us/step - loss: 0.0531 - accuracy: 0.9798\n",
      "Epoch 696/700\n",
      "99/99 [==============================] - 0s 122us/step - loss: 0.0384 - accuracy: 0.9899\n",
      "Epoch 697/700\n",
      "99/99 [==============================] - 0s 126us/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 698/700\n",
      "99/99 [==============================] - 0s 118us/step - loss: 0.0516 - accuracy: 0.9899\n",
      "Epoch 699/700\n",
      "99/99 [==============================] - 0s 118us/step - loss: 0.0280 - accuracy: 0.9899\n",
      "Epoch 700/700\n",
      "99/99 [==============================] - 0s 108us/step - loss: 0.0164 - accuracy: 0.9899\n",
      "model created\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               31616     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 34)                2210      \n",
      "=================================================================\n",
      "Total params: 42,082\n",
      "Trainable params: 42,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
    "# equal to number of intents to predict output intent with softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    model = load_model('model.h5')\n",
    "    print(\"model load successfully\")\n",
    "except:\n",
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "    # fitting and saving the model\n",
    "    history = model.fit(np.array(train_x), np.array(train_y), epochs=700, batch_size=8, verbose=1)\n",
    "    model.save('model.h5', history)\n",
    "\n",
    "    print(\"model created\")\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'],color='blue',label='accuracy')\n",
    "plt.plot(history.history['loss'],color='red',label='loss')\n",
    "\n",
    "plt.title('Model History')\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True,color='k')\n",
    "plt.legend(['accuracy', 'loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
